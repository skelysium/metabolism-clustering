{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libsbml as sb # SBML integration\n",
    "import numpy as np # for making arrays\n",
    "import pandas as pd # for dataframe conversion\n",
    "from pajek_tools import PajekWriter # for graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some info from literature\n",
    "iJO1366_rxn_nums = 2283\n",
    "ECC2_rxn_nums = 499\n",
    "\n",
    "\n",
    "def connectreduce(SBMLfilename, networkname, numberofrxns, writebool):\n",
    "    ## First: extract the relevent info from SBML file\n",
    "    reader = sb.SBMLReader() # open the reader\n",
    "    document = reader.readSBMLFromFile(SBMLfilename) # read the file into document\n",
    "    model = document.getModel() # and extract the model from the file\n",
    "    specieslist = model.getListOfSpecies() # get a list of all the species\n",
    "    rxnslist = model.getListOfReactions() # and of all the reactions\n",
    "    numspecies = len(specieslist.getListOfAllElements()) # number of species (non-unique; if 1 species is in two compartments it is recorded twice with 2 different SIDs)\n",
    "    numrxns = numberofrxns\n",
    "    speciesIDs = np.empty(numspecies,dtype=object) # prepare an array that stores only the IDs of every species\n",
    "    for s in range(numspecies):\n",
    "        speciesIDs[s] = specieslist.get(s).getId() # and add in all the IDs\n",
    "\n",
    "    ## Making Connectivity Matrix\n",
    "    connect = np.zeros((numspecies,numspecies)) # make an N x N connectivity matrix where N is the number of species/substrates. we will have that if two substrates with speciesIDs indices i and j are linked, connect[i,j] = connect[j,i] = 1; otherwise 0.\n",
    "    for r in range(numrxns): # for every reaction\n",
    "        rxn = rxnslist.get(r)\n",
    "        numreacts = rxn.getNumReactants() # find the number of reactants\n",
    "        numprods = rxn.getNumProducts() # and products\n",
    "        if numreacts+numprods>1: # if there are links to record...\n",
    "            substrates = np.empty(numreacts+numprods,dtype=int) # the total number of involved substrates will be reactants+products\n",
    "            if numreacts>0: # if reactants are involved...\n",
    "                for i in range(numreacts): # for every reactant...\n",
    "                    species = rxn.getReactant(i).getSpecies() # store its species id\n",
    "                    speciesindex = np.where(speciesIDs == species)[0][0] # store the corresponding speciesIDs index\n",
    "                    substrates[i] = speciesindex # add the speciesIDs index to the list of substrates\n",
    "            if numprods>0: # now do the same for products\n",
    "                for i in range(numprods):\n",
    "                    species = rxn.getProduct(i).getSpecies()\n",
    "                    speciesindex = np.where(speciesIDs == species)[0][0]\n",
    "                    substrates[i+numreacts] = speciesindex\n",
    "            for i in np.arange(len(substrates)): # for each recorded substrate...\n",
    "                linkindexes = np.delete(substrates,i) # make a list of the other recorded substrates\n",
    "                for n in np.arange(len(linkindexes)): # and for each of them...\n",
    "                    connect[substrates[i],linkindexes[n]] = 1 # put a '1' in the linkage cell corresponding to the two linked substrates\n",
    "\n",
    "    if writebool:\n",
    "        connectpd = pd.DataFrame(connect, columns = speciesIDs) # convert to dataframe for file saving\n",
    "        connectpd.to_csv(networkname+'.csv') # save the file!\n",
    "\n",
    "\n",
    "    ## Performing Topological Reduction\n",
    "\n",
    "    specieslinks = np.empty(len(speciesIDs),dtype=int)\n",
    "    for row in np.arange(len(connect[:,0])):\n",
    "        specieslinks[row] = sum(connect[row,:])\n",
    "\n",
    "    nodecolors = np.empty(len(specieslinks),dtype=str)\n",
    "\n",
    "    nodecolors[:] = 'a' # set all nodes to black\n",
    "\n",
    "    for end in np.where(specieslinks==1)[0]: # for each node with only 1 link...\n",
    "        prevnode = end\n",
    "        node = np.where(connect[end,:]==1)[0][0] # find and jump to the single linked node\n",
    "        nodelinkcount = specieslinks[node] # count the number of links\n",
    "        while nodelinkcount==2: # as long as the present node has 2 links\n",
    "            nodecolors[node] = 'g' # color the node green\n",
    "            nodelinks = np.where(connect[node,:]==1)[0] # find the two connections\n",
    "            nextnode = nodelinks[nodelinks != prevnode][0] # target the node you haven't been to yet\n",
    "            prevnode = node # make the jump !\n",
    "            node = nextnode\n",
    "            nodelinkcount = specieslinks[node] # see how many links the new node has. if it's 2, repeat; if not, find the next node with only 1 link and start over\n",
    "\n",
    "    for node in np.where(specieslinks==2)[0]: # look at all the 2-link nodes\n",
    "        if nodecolors[node] != 'g': # if it's not green\n",
    "            nodecolors[node] = 'u' # make it blue\n",
    "\n",
    "    # coloring branching hairs green\n",
    "    for bluenode in np.where(nodecolors=='u')[0]: # for each blue node\n",
    "        if nodecolors[bluenode] != 'u': continue # make sure the node is still blue; if not, move on\n",
    "        nodelinks = np.where(connect[bluenode,:]==1)[0] # find its links\n",
    "        blueblacklinks = np.empty(0,dtype=int)\n",
    "        for link in nodelinks:\n",
    "            if nodecolors[link]=='u' or nodecolors[link]=='a': blueblacklinks = np.append(blueblacklinks,link)\n",
    "        \n",
    "        if len(blueblacklinks>0): # if any of the links are blue or black...\n",
    "            blueblacklink = blueblacklinks[0] # pick the first one as the link\n",
    "            connect[bluenode,blueblacklink] = connect[blueblacklink,bluenode] = 0 # sever the link\n",
    "\n",
    "            # burning algorithm\n",
    "            burnlabels = np.repeat(-1,len(speciesIDs)) # label all nodes -1\n",
    "            burnlabels[bluenode] = 0 # except the starting node\n",
    "            nodes = np.where(connect[bluenode,:]==1)[0] # find its singular remaining link\n",
    "            stage = 1 # set the stage\n",
    "            while len(nodes) > 0: # as long as you still have more nodes linked\n",
    "                burnlabels[nodes] = stage # assign the nodes labels based on the current stage\n",
    "                nextnodes = np.empty(0,dtype=int) # initialize a list for the next stage's nodes\n",
    "                for node in nodes: # for each node in the stage...\n",
    "                    burningnodelinks = np.where(connect[node,:]==1)[0] # find its links\n",
    "                    if len(burningnodelinks[burnlabels[burningnodelinks]==-1])>0: # if it has unstaged links...\n",
    "                        nextnodes = np.append(nextnodes,burningnodelinks[burnlabels[burningnodelinks]==-1]) # append its unstaged linked nodes to the list\n",
    "                nodes = nextnodes # move to the next stage\n",
    "                stage = stage+1 # and update the stage count\n",
    "\n",
    "            if burnlabels[blueblacklink] > 0: # if the node on the other side of the severed link was burned (i.e. is still in the starting node's network)\n",
    "                continue # it's not a hair separation! make no changes and move on\n",
    "            else: # if we DID separate a hair\n",
    "                burnedsize = len(burnlabels[burnlabels != -1])\n",
    "                if burnedsize < 0.5*(len(burnlabels[burnlabels == -1])): # if the burned part is less than half the size of the unburned part (i.e., it's a hair)...\n",
    "                    nodecolors[burnlabels != -1] = 'g' # make the burned nodes green\n",
    "                else: # if the burned part is more than half the size of the unburned part (i.e., it's the network)\n",
    "                    # repeat the burning algorithm, but on the other side of the severed link\n",
    "                    burnlabels = np.repeat(-1,len(speciesIDs))\n",
    "                    burnlabels[blueblacklink] = 0\n",
    "                    nodes = np.where(connect[blueblacklink,:]==1)[0]\n",
    "                    stage = 1\n",
    "                    while len(nodes) > 0:\n",
    "                        burnlabels[nodes] = stage\n",
    "                        nextnodes = np.empty(0,dtype=int)\n",
    "                        for node in nodes:\n",
    "                            burningnodelinks = np.where(connect[node,:]==1)[0]\n",
    "                            if len(burningnodelinks[burnlabels[burningnodelinks]==-1])>0:\n",
    "                                nextnodes = np.append(nextnodes,burningnodelinks[burnlabels[burningnodelinks]==-1])\n",
    "                        nodes = nextnodes\n",
    "                        stage = stage+1\n",
    "                    \n",
    "                    nodecolors[burnlabels != -1] = 'g' # and make the new burned nodes green\n",
    "\n",
    "            connect[bluenode,blueblacklink] = connect[blueblacklink,bluenode] = 1 # finally, retie the severed link\n",
    "        # if none of the links to the bluenode were black or blue, move on to another blue node\n",
    "        \n",
    "    nodecolors[nodecolors == 'a'] = 'r' # make all the still-black nodes red\n",
    "    # print('green nodes: '+str(len(np.where(nodecolors=='g')[0]))) # DBUG\n",
    "    # print('blue nodes: '+str(len(np.where(nodecolors=='u')[0]))) # DBUG\n",
    "    # print('red nodes: '+str(len(np.where(nodecolors=='r')[0]))) # DBUG\n",
    "\n",
    "    # Note: for the two reduction steps below, I'm not sure what the supplemental material (p. 13) means by \"store [the removed hairs/arcs] as separate small networks together with the label of the [node/two ends] they connect to.\" I'll skip this for now and see what it affects.\n",
    "\n",
    "    # Half-reduction (removing hairs)\n",
    "    connect_halfreduced = connect # make a copy of the adjacency matrix for the half-reduction\n",
    "    # print('green nodes removed: '+str(len(np.where(nodecolors=='g')[0]))) # DBUG\n",
    "    connect_halfreduced[nodecolors=='g', :] = 0 # sever all links with green nodes\n",
    "    connect_halfreduced[:,nodecolors=='g'] = 0 # ^\n",
    "    nodecolors_halfreduced = nodecolors # make an updated coloring...\n",
    "    nodecolors_halfreduced[nodecolors=='g'] = '' # ...where green nodes are colorless\n",
    "\n",
    "    # Full Reduction (removing arcs)\n",
    "    connect_reduced = connect_halfreduced # make a copy of the half-reduced adjacency matrix for the full-reduction\n",
    "    nodecolors_reduced = nodecolors_halfreduced # same for coloring\n",
    "    # totredlinksmade = 0 # DBUG\n",
    "    for bluenode in np.where(nodecolors_reduced=='u')[0]: # for each blue node\n",
    "        if nodecolors_reduced[bluenode] != 'u': continue # make sure the node is still blue; if not, move on\n",
    "        node = bluenode\n",
    "        nodelinks = np.where(connect[bluenode,:]==1)[0]\n",
    "        prevnode = nodelinks[0]\n",
    "        redlinks = np.repeat(-1,2) # initialize the vector holding the two red ends of the arc\n",
    "        while redlinks[1]<0: # as long as there is still an end to be found...\n",
    "            nodelinks = np.where(connect[node,:]==1)[0] # find the current node's links\n",
    "            nodelinkcolors = nodecolors[nodelinks] # and their colors\n",
    "            if any(nodelinkcolors=='r'): # check to see if the node is linked to any red nodes. if so...\n",
    "                rednodelinks = nodelinks[np.where(nodelinkcolors=='r')[0]] # store any linked nodes that are red\n",
    "                if redlinks[0]<0: # if we haven't found the first arc-end yet\n",
    "                    redlinks[0] = rednodelinks[0] # store a red node as the first arc-end\n",
    "                else: redlinks[1] = rednodelinks[0] # if we have found the first arc-end, store the red node as the second end\n",
    "                if len(rednodelinks)==2: # if the blue node is linked to 2 red nodes (i.e., it's a 1-node arc)...\n",
    "                    redlinks[1] = rednodelinks[1] # store the other red node as the second arc-end\n",
    "                    nodecolors_reduced[node] = 'p' # make the blue node purple\n",
    "                    break # and break out of the while loop\n",
    "                else: \n",
    "                    prevnode = redlinks[0] # otherwise, prep to move in the other direction\n",
    "            else:\n",
    "                nextnode = nodelinks[nodelinks != prevnode][0]\n",
    "                nodecolors_reduced[node] = 'p'\n",
    "                prevnode = node\n",
    "                node = nextnode\n",
    "        # now that both red arc-ends have been found...\n",
    "        connect_reduced[redlinks[0],redlinks[1]] = connect_reduced[redlinks[1],redlinks[0]] = 1 # link the two ends\n",
    "        # totredlinksmade = totredlinksmade+1 # DBUG\n",
    "        # and move onto the next blue node\n",
    "    # print('red nodes connected: '+str(totredlinksmade)) # DBUG\n",
    "    # print('blue nodes removed: '+str(len(np.where(nodecolors=='p')[0]))) # DBUG\n",
    "    nodecolors_reduced[nodecolors_reduced=='p'] = '' # make all purple (formerly blue) nodes colorless\n",
    "\n",
    "    # question: where do the separated arcs and hairs factor back in? do they not factor into the clustering of figs 4A-C, only being involved in the 4D graphic?\n",
    "    # for now i'll just assume they're discarded except for fig 4D:\n",
    "\n",
    "    # remove all rows/columns of adjacency matrix pertaining to removed nodes\n",
    "    connect_halfreduced = connect_halfreduced[np.where(nodecolors_halfreduced != '')[0],:]\n",
    "    connect_halfreduced = connect_halfreduced[:,np.where(nodecolors_halfreduced != '')[0]]\n",
    "    speciesIDs_halfreduced = speciesIDs[np.where(nodecolors_halfreduced != '')[0]]\n",
    "    connect_reduced = connect_reduced[np.where(nodecolors_reduced != '')[0],:]\n",
    "    connect_reduced = connect_reduced[:, np.where(nodecolors_reduced != '')[0]]\n",
    "    speciesIDs_reduced = speciesIDs[np.where(nodecolors_reduced != '')[0]]\n",
    "\n",
    "    if writebool:\n",
    "        connect_halfreduced_pd = pd.DataFrame(connect_halfreduced,columns=speciesIDs_halfreduced) # convert to dataframe for file saving\n",
    "        connectpd.to_csv(networkname+'_halfreduced.csv') # save the file!\n",
    "\n",
    "        connect_reduced_pd = pd.DataFrame(connect_reduced,columns=speciesIDs_reduced) # convert to dataframe for file saving\n",
    "        connectpd.to_csv(networkname+'_reduced.csv') # save the file!\n",
    "\n",
    "    ## Converting adjacency matrices to edgelists for Pajek graphics\n",
    "    if writebool:\n",
    "        connect_edgelist = np.empty((len(np.where(connect==1)[0]), 2),dtype=object)\n",
    "        nextedgerow = 0\n",
    "        for row in np.arange(len(connect[:,0])):\n",
    "            for col in np.arange(len(connect[0,:])):\n",
    "                if connect[row,col]==1:\n",
    "                    connect_edgelist[nextedgerow,0] = speciesIDs[row]\n",
    "                    connect_edgelist[nextedgerow,1] = speciesIDs[col]\n",
    "                    nextedgerow = nextedgerow+1\n",
    "\n",
    "        connect_edgelist_pd = pd.DataFrame(connect_edgelist,columns=[\"row\", \"column\"])\n",
    "        writer = PajekWriter(connect_edgelist_pd,\n",
    "                            directed=False,\n",
    "                            citing_colname=\"row\",\n",
    "                            cited_colname=\"column\")\n",
    "        writer.write(networkname+\".net\")\n",
    "\n",
    "        connect_halfreduced_edgelist = np.empty((len(np.where(connect_halfreduced==1)[0]), 2),dtype=object)\n",
    "        nextedgerow = 0\n",
    "        for row in np.arange(len(connect_halfreduced[:,0])):\n",
    "            for col in np.arange(len(connect_halfreduced[0,:])):\n",
    "                if connect_halfreduced[row,col]==1:\n",
    "                    connect_halfreduced_edgelist[nextedgerow,0] = speciesIDs_halfreduced[row]\n",
    "                    connect_halfreduced_edgelist[nextedgerow,1] = speciesIDs_halfreduced[col]\n",
    "                    nextedgerow = nextedgerow+1\n",
    "        connect_halfreduced_edgelist_pd = pd.DataFrame(connect_halfreduced_edgelist,columns=[\"row\", \"column\"])\n",
    "        writer = PajekWriter(connect_halfreduced_edgelist_pd,\n",
    "                            directed=False,\n",
    "                            citing_colname=\"row\",\n",
    "                            cited_colname=\"column\")\n",
    "        writer.write(networkname+\"_halfreduced.net\")\n",
    "\n",
    "        connect_reduced_edgelist = np.empty((len(np.where(connect_reduced==1)[0]), 2),dtype=object)\n",
    "        nextedgerow = 0\n",
    "        for row in np.arange(len(connect_reduced[:,0])):\n",
    "            for col in np.arange(len(connect_reduced[0,:])):\n",
    "                if connect_reduced[row,col]==1:\n",
    "                    connect_reduced_edgelist[nextedgerow,0] = speciesIDs_reduced[row]\n",
    "                    connect_reduced_edgelist[nextedgerow,1] = speciesIDs_reduced[col]\n",
    "                    nextedgerow = nextedgerow+1\n",
    "        connect_reduced_edgelist_pd = pd.DataFrame(connect_reduced_edgelist,columns=[\"row\", \"column\"])\n",
    "        writer = PajekWriter(connect_reduced_edgelist_pd,\n",
    "                            directed=False,\n",
    "                            citing_colname=\"row\",\n",
    "                            cited_colname=\"column\")\n",
    "        writer.write(networkname+\"_reduced.net\")\n",
    "    return connect, connect_halfreduced, connect_reduced\n",
    "\n",
    "con_iJO1366, conHR_iJO1366, conR_iJO1366 = connectreduce(\"iJO1366_SBML.xml\", \"iJO1366\", iJO1366_rxn_nums, True)\n",
    "con_ECC2, conHR_ECC2, conR_ECC2 = connectreduce(\"ECC2_SBML.xml\", \"ECC2\", ECC2_rxn_nums, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
